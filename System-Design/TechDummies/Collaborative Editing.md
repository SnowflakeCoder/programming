# Collaborative Editing

Google Docs System design | **Operational transformation** | **Differentail Synchronisation**

Design collaborative editing applications like Google Docs, Etherpad and Mockingbird.

## Collaborative Editing 

Letting multiple users work on the same copy of the document. The document could be either text or rich text or painting or wireframes or anything. We are just letting **multiple users collaborate and work on the same copy** of that particular document. So if there is one document and multiple users whose working on it, so all they need to do is **share the DIFF** of what all the different people are editing in their local copies or local clients. you just need to **keep sharing between different users** who are working on the same copy. But it is not that simple because same user can delete a particular line, line in between, adding words in between, **changing the font** or it could be anything.

**Collaborative editing is complex** because of two main reasons. 

- **concurrency** - because more people are working on the same document at the same time.
- **latency** - because guys working on the same copy of the file are in **different places** and they are connected through internet. So that means that there is a **latency between each and every clients** when they are sharing the DIFFs.

## LOCK

Lock can be used whenever we are **accessing shared resources**. But we cannot we use lock to solve this particular problem. Its possible that hundreds of people editing the same Google Doc at the same time, so even if we want to give a **turn-based editing write** to each and every user it's not going to be possible. Using lock is called as **pessimistic concurrency control**.

## Lock Free Architecture

So we need is we need a **lock free architecture** or **optimistic concurrency control**. What that means is we optimistically think that nothing is going to go wrong even though we give access to the to all of the users who are editing the same document. How do we solve is by **taking the versions of each and every stage of the particular document**. let's take an example there is a user-A  and user-B, both are editing on the same document from their browser, so **how do we sync the information** which both are working on so that we can show what user B is typing on the screen of using A and what user A is typing on the screen of user B.

There are 3 different **strategies to sync the information** between the users.

- **Character by character or event based syncing** -  
- **Line by line syncing** - 
- **DIF syncing** - DIF shows you all the difference, all the edits you have made to that particular file. just take the **copy of the DIFF** and then keep sending back and forth so that we can keep on passing on either side of the browser or the local copies.

### Event passing or character by character syncing

As soon as a user types or deletes or **any key event happens** on the local copy of a particular document we need to keep sending that information. Not just any addition or deletion or updation, even the font changes and **any changes happen to that document should be treated as an event** and  should be keep on translate to all the other guys who are also editing the same document. That is **sending bits and piece of information instantaneously** like every now and then.

Event passing is also called as **operational transformation** and is **used by Google Docs** for syncing the information between multiple clients and keep converging the document to the one single. 

### Line by line Synching

Second approach is we can **take line diff** or the whole line and we keep on **sending the updates periodically** or as and when there is more changes happen to that particular line altogether. But the problem is **what if the other user also have edited a lot of the characters in the same line**. So it's a bit **clumsy to resolve the conflicts**. 

### Differential Synching

You **get the diff periodically** from a user and **send the whole diff** (text) from user A to user B and do the same thing on the other side like from user B file get the diff send the DIFF back to user A and then **patch it on both the sides** so both users have the same document state on either side and that is called as **differential sync**

## Operational Transformation - In Depth

Operatioal transformation is an **optimistic concurrency control** mechanism. It allows two editors to **modify the same section of a document** at the same time without conflict. Or rather it **provides a mechanism for sanely resolving those conflicts** so that neither **user intervention nor locking** become necessary. In operational transformation, every changes or every modification to the documentation is **represented as an event** and each event will be transferred back and forth from the server to the other clients.

Basic operations in a text editing are insert, delete, update and retain. But there can be numerous operations in the Google Doc like change in the font (size & style), change in the color, changing the background color etc. 

For now let's take only these four basic operations. whenever we are sending the information from one guy to other guy the message will look like something like 

> **Operation(Character, Position)**  -  what operation, what character and where.

**Example** : insert(A, 1), delete (B, 10), update (x,y,20). Each and every operation should actually carry the information about what character is modified and what position. 



what happens when both guys are started to update the same document.



 consider we have a document but started with you know sample information like power this document has text 80 in it a at position 0 T at position 1 so this is the document ok this is actual document which we are starting to edit so there is there two guys guy one guy Lee number two and they both have opened the Google Docs on their browsers now both will actually see 80 80 right so that is clear so now consider this guy and this guy start to edit this this particular text at the same time now let's see what happens so this guy's intention is to kind of delete T so what operation he performs is delete T act position 1 that is 1 right so we let's from 0 1 so he did it steal from position 1 so that's the operation he performs now the state of this text or the document will be a right so in the same time in the parallel universe or the other side of the internet so this guy the kind of a tool what he is trying to do is insert operation instead insert h2 position zero he's trying to create hack word using a key so what she's trying to do is insert H at position zero now this document state will become H a D right both are correct now it's not the end of the story because whatever operation we perform on this site should be transferred to that guy and whatever operation which was performed on this side should also be transferred back to the other guys right since only two guys are operating on this document we just need to transfer it back and forth so now this operation let's send it to nine number two okay and this operation will send it here so now what happens now as soon as we receive this information insert hedge at position zero now let's execute blindly what happens we insert H at zero position that is so since this is is the zero position if inside it it will slide back so it will become H a right so now this is the latest state of document and now since this information was sent to guide number to delete T at position one but if you actually see at position one there is no T even if we go ahead and do it something acquisition fun we end up having H and T only now there is a first of all we have a mismatch because we never had tea at position one in this is nothing document even though if you override and delete one at position in the in the text we delete a and we only retain HD we can't just find T instead of going to positioning just search T and delete it will not be a correct procedure because there can be numerous team in the text which is in the document in this example there is only one occurrence but actually there can be multiple occurrence so we can just search by the character on the date instead we have to depending on the position so we deleted a so we end up having Hetchy so if you see here both guys now doesn't have this same copy of the document because the intention for off collaborative editing is to have a you know convergent document or the document should always converge into one single state if you have multiple state if there are like a number of guys who are editing the file will have an end number of different copies of different versions of the file created we don't want that to happen we always want one copy of the file to be there and that is the source of truth and that should be always consistent for all the users right how to make it consistent if you just send the operation back and forth if you just broadcast operation to all the other guys who are a DJ it won't work because we just saw here right because we have the document state is not same on both the side here we have headshake and we here we have HT so what operational transformation I just explained was to keep on sending the I know granular updates back and forth but we need that but it's not happening so here is actually the core part of operational transformation comes into the picture the formula looks something like this here is simple explanation in you know plain English before that before doing that and just tell you the core objective of this particular formula we just need to somehow modify these operation which is somehow relevant to this guy and whenever the operations of a guy number two sends to the other guys we have to modify this particular operation which should be suitable to be applied to other guys document state because we can't just lightly apply the you know operations of one person to the document of the other person so what we actually is that kind of kind of transformation of the operations sent by the users to the different users they are little named what I said was operational transformation what that means is we have an operation we had to do what a transformation of this operation which holds good for the other user who is concurrently editing the document or who is collaborating with us so let's go back and look at the followings again so this formula means that the transformation function takes two operation at the end given any given part of the time that is operation a which we have done and the operation which we have received and then we have to do a transformation before expending that I just forgot to explain tell you one more thing so every time we don't actually send me I know information directly from user a to user B and use of me to user a are 1 to 2 and 2 to 1 or if you have one of our users like 1 2 and there are couple more users we're not going to broadcast these operation directly to more number of users and we don't receive the operation from all of the users so instead we always have one authoritative server or you can call it as a server or sessions everywhere where you name it so control let's make this is a server ok so when these two guys open the document he'll give this state from the server with a copy of the document which is there in the server and any operations which we perform we always send it to the server and the server intervals in turn sense that those operations to all of the other users who are collaborating for the same document so basically whenever we are exchanging some information it is actually in this example is not the guy number two we are kind of talking to the server I just told you that we are just at conceiving from the you know guy number two to one and one to two actually it's happening by for this guy he is receiving the information from the server and for this guy he is signaling information from the server so think it that way so in case of this problem so this transform function takes two operation operation a and operation B think operation a as the local operation which we apply and B as the operation which we receive from the server and this some function produces a pair of operation that is a dash and B dash and these operations can be applied to the other guys or the counterparts end document state to produce the exact same state when these operations are applied on both the side so to just to show it graphically and this is how it looks this is called as I don't diamond graph or representation of the operational transformation where it shows there is so it usually it is represented as the the blue line is the client side operation and the grey line is the operation which will you say from the server so a is the client operation and B is the server's operation so so from from a single state that is the tip of the diamond we actually apply operation a and we diverge on the you know left side and when we apply it on the server side it diverge to the right side that's the gray line okay so now the document is not in the same state it actually diverge and then we have to apply operation a which was applied on the client side on the other side and we have to apply operation B which was applied on the server on the client side so that is so now I will either just write it graphically to make you guys understand this from say they started with a state of the document that is a tea right so we started from a state 80 so this is considered this is a starting point and then we applied operation a write operation a and then we arrived at state a I mean the reference state here actually we applied operation a and then we got output a and then what we did is on the server side also badlani there was one more operation which was applied what happened there was we applied operation B so I called operation this as operation B and this operation right so on this side when we apply operation B we are able to state hat so here we had the worst a hat so now what we did in this case was we sang this operation leave on this side and we send operation a to the other side and then we are ready to demonstrate so what we did was okay we send this operation on this side so we got operation B over here and we applied this operation on this and we arrived at what H a rights so we are at H a and when we send this important this operation over here we applied it a and we arrived at a different value h d so this is not correct because this of ashwin same state we are not arriving it so this is this is not stable so instead of sending operation a back operation a itself to the other side what this operational transformation says is we have to send a - and the same holds good for the other side also instead of sending operation be directly to the other side we are dealing sign in state B - okay how do we get a dash and B dash is what the formula says so we have to pass these two operation transform function that is say a regular index or when I pass a comma B both operation it automatically not automatically so we had to actually implement operation transformation algorithm so he gives out a dash and B dash so that these operation on applying on the either side we arrive at the same stage that is we hire CH h a on this what we are supposed to do is so when we sent X form the transform of this operation that is deep operation and then insert operation we should have got instead of deleting t comma 1 we should actually get delete delete' t at what position T comma 2 now what transformation happened was the actually operation which we had on this side was the t comma 1 right this transformed function understood based on the intent and the inner context a got to know that the document was modified and we're not supposed to delete one we had to delete position to and that's is T and also it should give out one more operation that is insert of the insert H at zero position instead of inserting at zero so it understands that inserting a check zero position itself will retain the integrity of the document so it gives out the same operation so by passing these operations from the either side we actually arrive at the same state that is fetch it okay so here it just to rewrite this example so if it all passed these two operations then transferred it or applied it here we have got delicti to write and H inside H at the zero position so we just need to change one too many when you transform z-row so we could have actually got hm yes so that's what we are both sorry we arrive at the same state of the document I'm not sure I have explained it well so that you guys can understand it or not just go and read about operational transformation and there's tons of features in operational transform as well like supporting we do one move and everything so this is a very simple form of whenever representing the diamond diagram actually this grows to even bigger okay so far we learn to operational transformation 

## Differential Synchronization - In Depth

it's more like taking get div from the modification you have made to that particular file and taking the different applying the patch on the server or on the other clients say in the setup I have server and I have client think these two companies are in client side and these two components are in server side similarly more number of clients are connected with the same server so if three guys are working on the same copy obviously we need to connect to Google Docs severide so there is one guy connected to the server and there's one more guy said I just mentioned for the sake of presentation this guy is also connected to the server and this guy is also connected to the server so total you guys are connected and I'm gonna take only one client and this server to show you how the differential synchronization works so whenever will be open a particular Girl Talk we always start with the initial state so in this case this is called a splined copy and this is client so on the client side itself we need to maintain two copy of the same document on the server side as well we need to maintain to copy this is the actual copy end for the very first time we actually have our duplicate copy of the same step so when we start all these four copies are in the same state so obviously so this is the internet connected to my internet right so they are like in a different places altogether so now when say for example this client ID it's something on in here okay so there is some modification a user has modified the client copy this is where the actual editing everything happens consider this as the browser and this is in memory of the browser itself okay so user has to get at something over here now we need to get the div and send it to the server to keep the document always in the converge state so now we're ready to do is on the way the first step we need to check the data in the memory with the data which is there in the latest copy which we edited and get the diff so we got the diff now what do we do with the diff is we need to send this be as simple as that okay we have said that as soon as we sent it we get to before user edits we need to replicate the copy whatever we had to the client cop so now these two are in the same state now the diff is sent to the server now what happens here is when the diff is sent to the server side obviously here also we have this server actual copy and the server copy one more copy for some reason I'll tell you why so first what we need to do is we check the div with whatever reason controls we will name this batch okay we have sent this patch over here and we need to check the diff again with the server copy and then we have to get the deal because this copy without being edited by some of the times right so it will never be same as this it might be but most cases if more clients are connected to the server the actual copy here from being diverged so what we need to do is on the batch we need to check with this you know server copy and that get the death and then apply to the so copy and also we need to do the same thing on the server also the the data which we have for the doc the server also need to get to live and up light okay now we have successfully sent the updates which were made on this client to the server so once this replication happens on the server side what happens is server should broadcast it back to all of the clients how tall is it doing it again does this in the same way how we did it on this side it's basically takes diff from these two okay checks for different creates a patch out of it and that takes us free shot or takes a copy of that state before some other client comes in edit that arbitrarily so we have to keep on taking the copy of the supper also because because of the concurrency it's it's that simple so whether we are taking a copy or we had to have an blocking mechanism are some mutex or some things so that at any given point of the time while we are taking a copy of the server data it shouldn't be edited by someone else so it's just that we have to maintain that Adamo City and then this patch should be sent back to the client and all the other clients okay so in this case this still there is no need to send it back to this kind even if you send it what happens is the same strategy applies here also we'll check it here essentially there will be no diff because we actually created this patch out of the same copy so the same diff is coming back to us so essentially boiler in the same state so we have nothing to patch so we'll not have but for the sake of process I'm just going to mention can affect the different of light if this patch was because of some other claim maybe this guy's sent some updates then we don't have we were supposed to apply it to the client copy and also to the working copy of the client also here also you get the death and apply over here on a high level it is very simple algorithm it's just that taking it if I plan the patch and then keep the state on the server side and server acts as a source of truth if this guy is when offering for some reason and he has diverged too much and although the clients have diverged in a different way it's actually a very big conflict in that case we have to take a decision whether we have to kill this change beggars you to a different version of a copy because we can't successfully merge it or just discard although you know I want to other copy asking for the user ok there is some you know much conflicts or something I mean we can handle it in our different strategies that is up to our use cases so this is the differential synchronization 



Vito T or B differential synchronization there is one important thing which we need to follow all this say the this is a simple representation where the server and client to one client here and one right here that is flying one fly too so I you select whichever algorithm you want but one thing is very important that you always need to make sure that there is a state which is maintained on in the server because these clients can go offline any time this client can diverge any time or they can do anything so we need to always make sure we are actually maintaining the state of the document and all the histories or the updates are kind of saved in some place be it in the time series TV or bade in your Cassandra or between our DBMS it's up to you guys look if you look at the scale there are too many updates right so I you know recommend to go for no sequel or time series TV so that you also get a timeline of operations and also you can track what user has modified what particular part of the document so it looks something like this say operation kind of kind of stack of operations which we have on the server side which also tells you what time which user set and did work modification to the document that way we can also reach it at any point of the time I mean that is not necessary that is kind of disaster recovery or kind of all this management but anyway we have the complete record of how the document evolved into the current state yes and also one more thing is we have to always look for acknowledgements this client will keep on sending the diff or events in case of OT or anything right so there will be keep on selling any updates and they will be keep on receiving the updates so whenever the client sends an update to the server before they the next option they should definitely wait for the acknowledgement back from the server that way that way the clients can make sure that the operation the previous operation is properly applied on the server side or not because if the first operation failed and if the client is already something the second operation because of this operation got failed it is not correct to apply this operation because the very before the operation before that has failed it would definitely cause you know conflict and in a conflict resolution will be difficult or it will just cause unnecessary complication so always while shalini of operations we had to wait for the successful previous acknowledgment and then only make sure that you keep on setting the operations





## Diagram









## High-level Overview

This is a service-oriented architecture Diagram to keep it simple. 

On the left side you can see there are three clients connected, so they are **interacting with the API gateway** for any operation to be performed. Operations like get the comments, send notification, grant permission, ask for the permission or anything it's **always goes through the API gateway**. So once the API gateway gets the request it actually does the **request composition**. It actually calls the **authentication service** to check your request is authenticated or not. This service takes care of authentication, authorization or permissions. **Comment service** takes care of the comments and it is directly connected to the **NoSQL DB** as we are expecting a lot of comments on the document and we also want to have a **hierarchical view of the comments** (so better to use some **graph DB**) also. 

we have email, GCM or notification service which takes care of all the notifications (GCM or APN). we have **core app services** which provides all the APIs to **land to the main Google Docs page** or if you want to **export the document** to any different format or want to upload a new document and convert it to a Google Doc etc. We have **RDBMS DB** because certain things we need to be consistent and we need ACID properties like users, documents, copy of the document and all the different resources. We also have **time series DB** and **Redis**. Time Series DB mainly used to **store all the different historical operations** performed by individual user on a particular given document.

Other important components are **node JS WebSockets**, **operations queue** and **session server**. When the **first time the user connects** or opens the doc, he will hit the API gateway and he loads the document and **if he has the permission he will get a session established**. Once he go to the edit mode and then he gets a **node JS WebSocket connection** which is established from the **browser to the server** always on. So now he can efficiently keep on **sending the small operations** as and when he wants and then **receive the updates from other clients from the server** immediately as soon as they broadcast it. So this design mostly for **operational transformation** so I'm expecting the **message size to be very small** so WebSockets are best for those kind of operations. 

All these operations should be **ordered in a queue** because the server should always prioritize one operation over other. So it's better to put it in the queue and then keep on ingest as and when the operations from all the clients for that particular document keeps coming in. So we have operations queue where all the operations are queued over here and the **session server** will keep on ingesting those operations and it **keeps its own state of the document** and that acts as a **single source of truth**. Session server also **keeps on saving a copy of history** into the **time series DB** so that if you want to **revert it back** to a particular version or if you want to check **who edited this particular line** or this particular word we can easily get that information from Time Series DB. If you want to have a **tree kind of representation** or a graph representation of how this particular line changed or document changed you can actually use **graph DB** as well and there is a **cloud storage** if you want **to save the document** as it is or if the user converts the document to PDF or HTML or any other format and if you want to give them a link to get the document to download it. So you can use the cloud storage to save the exported document 

## Websockets



now let us talk about WebSockets most of you guys know why a mini habits okay several advantages for the newcomers I'm gonna explain it anyway so you can actually use HTTP Ajax to send the updates to the server and receive in the response itself basically we need to keep on pulling you know frequently and then get the information and send the information but that is not very efficient because every time when you make an HTTP call it has to do a handshake establish TCP connection do a handshake and then send the information receive the response and this is time taking and also it is overhead so to keep the connection lightweight we have to definitely go forward WebSocket other than HTTP attacks we can actually use long polling or comment like our implementation but those are not much efficient and also every time we make it should if we call the header size and everything will be really high so we may have WebSockets it actually makes connection established in connection once and once it does we can actually send and receive the messages seamlessly in real time this actually helps us to keep on sending the information as and when the user modifies the document we don't need to keep on pulling periodically so that's where we are saving the bandwidth and also overhead on these you know browser also here we have a connection open if the user is editing something then only we sell it or if you have any updates to be received then only we will receive the message like several reasons the message we don't need to ask server do we have any information when we have a connection open server will keep on sending the updates to us so these are the advantages having been all WebSockets and on the server side we can actually use nodejs which is well built you know a synchronous server which actually has like with messages and which is built for these kind of use cases 



and also when we use WebSocket along with the **Redis** we can actually provide a lot of cool features like we can actually edible chatting feature for the users who are editing the document that can be easily implemented with the WebSockets and the race and also we can in real time show where exactly the user is editing their cursor in different colors as and when the user joints to collaborate to edit that particular document this is all possible just because of the WebSocket you know real-time communication 



## Micro Service

so now we're a little bit explained about why I have chosen to use micro service kind of architecture for this particular application because there if you see there are different kind of services or today that there is a notification service there is a comment service there is a session service there is an operation service there are different API right if you see all of these different services I can't make all of the service on to a-1 surveys and it will look I don't want to make it a monolithic service if one service goes down it just pulls everything along with it so I have identified very important services I can just deploy them in a separate as a separate services it will never impact we know failure of one service will never impact say for example if our common service goes down our dog editing you know saving exporting port and everything is still functional only the comment services will not be available I mean that's fine instead of taking down the whole app it's fine to have I have one service down and all the others are up and running you know very well so that's a reason why I am going with the micro service architecture so first of all it gives you the simplicity and modularity of the different services we can maintain different services without affecting other services and the second thing is it's very easy to turn up and we can develop any services faster without affecting anyone and if you want to talk from the developers perspective and management perspective also managing you know some small service separately itself is much easier than managing the whole monolithic service and also if you're a new developer the company just now and if you give the call for the whole Google dollars it's very difficult to understand you face the monomyth capitalism but instead if it is our micro service you can just view the comments section cord if you tell them to understand it's much easier to understand the whole core and you can easily debug anything or you can easily add any services into it but if it was a monolithic there is a hell lot of dependencies in between different services we can't just separate those things even if you built it as a module but it will not be that easy as a service it is much easier to understand develop and maintain and deploy also and also the freedom of using different technologies that I can say for example for all the AKS I can use Python as you know programming language to develop that and I can use C++ for handling the you know operational transformation itself because it is proven that C or C++ is kind of much faster when you have a lot of operations involved in it it's fine I'm I have that freedom to you know implement operation transformation using C or C++ and implement all the API is and all the comments service and everything is in Python or Java that's one more advantage if it was monolithic so you will actually tied up to the old you know code except and you have to even if you want to add a new service you are kind of tight on lock down to the old technologies and you had to use the same overtake but in this case it's not like that you can actually use any different static for any different service and then you can deploy independently the negative talk to each other using RPC or you know protobufs or you know a rest or anything like that and also the poor thing is scaling is easy you can just scale up the service which is getting more traffic say for example if the if the people are not actually using the chat services it's fine we can just scale down and then we can save a lot of resource and we can scale command service only and then we can scale APs we have a granular control on the services where we want to scale or beyond to downscale so it will so these are the advantages of having you know micro services



## API Gateway

 so let's learn about a gateway when I say the system the Google Doc system is designing micro service architecture obviously you must be thinking that there are so many services how the clients will know that know about all of these services and how do we deploy and everything right so for all of those things a a gateway is the answer all of the micro services are usually deployed in dock like you know strategy right each and every micro service is built into a doctor as it whenever we want to scale we actually because the number of doctors deployed and everything so this all can actually happen by our one system itself like for example kubernetes for example or dr. Swann or there are so many other technologies available there so kubernetes also act as a a que get a PA gateway what it actually does is as the name indicates it is the main entry point for the offer all of the backend services this is the gateway where the clients will actually hit the request key so when the client make a request the request will first land at the take a tree and then the aka gateway decide which micro service or which instance of the micro service where to hit that hit these are ways to get the response back to send it back to the client so these are the advantages of having a pee-pee so the first one is single entry point so the clients will never need to know for this service where to contact or which IP to contact of which static IP or which force name it's always one entry point one IP is well which we it's easy to configure so there's always a single entry point and a PL composition so when you have a micro service say for example just to get the product information this is just for example just to get a product information in an Amazon page for a product we might need to hit you know product related information recommendation no reviews ratings number of items left in the inventory all this information right so there can be about 10 to 15 APA calls we might need to hit if we don't have a take effect because all of those are different services we have dog is equal all of the different services to get all of the information but if you have a PA carry what happens is we just need to make couple of calls one or two calls just to email you pay internally a take a frame what it does is when the deposit lands to the API gateway it internally does the API composition what is API composition say if I'm pretty custom for our product API it knows internally based on the configuration that we should call five to six different services what are those services are it automatically and a secrecy and parallely which calls fight since different calls either by an HTTP arrest our RPC aim to be messaging technology or any other protocols just to get to remove those respective services and get the response it actually calls the product API recommendation API imagery API you know reviews API rating sake a and collect all the information into one response and sends it back how cool is that we just made one call and the aka clay took the responsibility of calling all the different services and collect all the in our result and set it back and this is very easier for the client-side to get the information of all the different services right so that is one second one is securely so therapist will be keep on adding services and how do we make sure that all of the services if he doesn't have a key we make sure that all of them are properly protected are they authenticating not or checking the Commission's or not so if you have an area trade we just need to hardwire for only yeah here for all the requests but the negation is must so kind of these services are kind of safe inside so these services are kind of hidden inside the network the EPA gateway so no one from the outside can access from the from the customer or the client perspective only the EPA's which are exposed can be accessed for all of these different micro services are kind of hidden inside so that way we can actually maintain security easily in case of Google Docs the same thing right we shouldn't let others to see the comments for the document which he doesn't have access to or you shouldn't be able to communicate our edit the document which here hasn't have an access to write so all these things can be easily handled in a takeaway and the third way is dynamic service discovery services there is a different and difficult problem when we have you know micro service kind of architecture because when you have number of micro services in the backend because of the auto scaling and down scaling and you know different versions of the same service deprived and everything happening we can't have all my static IP stew all of the services and how does the client knows where are these services deployed what is that IP or what is the DNS or whatever or the domain name so that is kind of difficult but that is solved easily using a take it because the client should only remember the aka gateways IP or domain name and the API gateway automatically will keep on talking to the service registry where it has the this issue of what service is in which dynamic IP and everything so it automatically hit still respective IP and gets the information back and gives back to the client so that way service discovery is much easier the Forest Service partitions are hidden as I mentioned these different micro services are hidden behind the KKK and that's one thing and also today I might be thinking just the comment bar all and take a different example in the Amazon you know product page selves if I have a ratings and reviews itself as one service today but tomorrow I might think ok I want to split that into toolbar I want to make ratings itself as a separate service and reviews as a separate service if I didn't had the ek gateway it will um be tedious process because I already change the client code also to you know make two different calls one for rating and one for you know Rubeus because of the aka gateway I don't need to do that at all so I just need to split that into two different service and then reconfigure the API get the configuration to call one more you know a PA call to get the rating separately and W so we can call it together that way service partitions are also fitted I already spoke about hidden micro services right so in the system is very important circuit breaking so this is very important so there's one one module which is developed by Netflix called does his tricks you can take a look at that it is a very good you know application to handle circuit breaking and in case of when if you want to what is the kit braking means say for example I have a a cake all making and it in turn making making about five calls okay just so it's making five different cause for some reason my rating API is overloaded in this case this product a a called will be keep on waiting until this request is survived I have got it restful the response for this this this this I am just waiting for response for this particular microservice for the ratings to receive this is kind of blocking right because because of just one micro service is not responding the the whole trade itself is blocked and in turn we're not able to send back this much response to the client so you said we can actually so all these ten problems right chemists are using a separate baking pattern so we can actually set a timeout first on each and every micro-services if when the API if it makes a call to all of these different micro services if any of the services didn't respond with a given set I don't hide timeout just written all the response whatever you have so far and you can set a priority also say if you have the product information just send it back but if you have all the other information but not the product information just discard everything and send 500 out for whatever 500 or something so that all composition you can actually easily make and I'm supporting is when the product EPA understands that the ratings micro service is not actually responding like the waves was supposed to respond it can actually stop making the question a service at all it will just stop making liquids because it understands that this guy is kind of order it so it's not as formal if I keep on making the request it will just keep on cascading be no requests and then the service will never recover so it just stops sending the quiz to the waiting's APN so it lets ratings api to recover and and become healthy so after some time oddly maybe after 10 minutes it will just make one call to check whether the rating api is up and running heavily healthy or not if it gets a response then it considers that the rating api is up and running and then it keeps on making their you know ratings micro service call whenever there is a product take a call if it doesn't respond other ratings if it doesn't respond then it will just think that the service is still down and it will never make a call so this is what called a self circuit braking and this is very essential when you have a micro service architecture in case of Google Docs collaborative editing also so if the you know operations handling part itself is down the whole thing is down anyway but operations handling part is up but other things like comments down or you know because of statuses down or maybe the online users is down it's fine for us the document about data and operations is very important we can that the let AKA or the APA query written the response back and forth and wait for other services to recover



## Google Doc Front-End

How we can actually implement Google Docs front end ? use **angular** or any other frontal technologies. But the important part is you **can't really render the actual Google Doc on the browser**. Whatever you see (the Google Doc) whenever you edit is actually the **HTML page itself**. So whenever you adding a new line you are actually kind of **adding a div or span or paragraph or something like that**. So you are **not actually not editing the doc on the browser at all**. It's all the HTML file and JSON implementation only. 

**This is all the HTML itself** what we are editing so it **doesn't matter** you're actually implementing Google **Docs or excel sheet or rich text or just a plain text**. So what are the features we support in the front end is only the features which are **actually supported in the actual Doc / DocX**. 

We have to give the option to user to download the content user has written on the browser to as doc or docx or PDF or HTML or any other different formats. 

we can actually use you know **Java script web workers** in the backend to have a parralel thread operations one which keeps on taking care of sending the operations and receiving and acknowledging and waiting for server to conform and everything because as we know that **javascript is a single threaded** if you just give all of the tasks on to one guy it will be heavy overloaded so we have to use **JS web workers** when one thread which kind of **handles the operations and transformations and acknowledgments** and the other worker which actually **handles the actual features** of all the docs which is supported.

It's better to use HTML and there are lot 's of **open-source JS implementation** for collaborative editing is available like share JS.