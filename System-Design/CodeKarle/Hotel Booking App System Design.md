# Hotel Booking App System Design

**Airbnb** | **Booking.com** | Hotel Booking App System Design and Architecture





but just one thing to call out we will be looking at a very high level architecture of the whole system and not at a lower level class diagram and all of that in this video so before we jump into the problem let's first look at the 

## Functional requirements

We have two major consumers of this application. 

- **hotel side of users** (Hotel manager)
  - Onboarding
  - update their properties like changing price, adding more rooms etc.
  - Booking details and revenue.
- **consumers who want to book** the hotel  (User)
  - search for a hotel with some filters - pricing, number of rooms, 3 star or 5 star etc. 
  - book the hotel.
  - check bookings.

**Analytics**

## Non-functional requirements

- Low latency
- High availabilty
- High consistency

## Scale

- 500K hotels
- 10M rooms.

**Assumptions** - there will never be a case  such that there is just one room available and there are thousands of users who are wanting to book that, at max there are two three users who are trying to book that and we will be able to use that assumption for our leverage at later point in time.

## Diagram

![Hoel Booking System.png](https://github.com/SnowflakeCoder/programming/blob/master/System-Design/CodeKarle/images/Hoel%20Booking%20System.png?raw=true)

## Data Flow

### UI/APP for Hotel

This is the UI that we give out to the hotel managers, it could be either **a website or a mobile app**. Through this UI **they would come and onboard onto our platform** and they use same UI to **modify the property**. 

#### Hotel Service

This UI talks to a **load balancer** through which it's it talks to a **hotel service**. This is basically a service which **manages the hotel part** which is basically the onboarding and the management. There could be **multiple instances (nodes) of this hotel services** to handle the spike in traffic so this a **horizontally scalable component**. 

Hotel data is a very much **relational data** and it doesn't have a scale problem so we'll be using a **clustered MySQL** here with one master and multiple states slaves can be added as and when required if let's say there's a huge spike in three traffic we can add more slaves but this data resides within mysql database okay now let's just say any image is added so hotels can add images about the rooms about their whole building and all of that all those images would be stored into a cd and the reference to the cdn which is basically a url of the image would be stored in the database and that url would be sent out to customers and whenever they want to render an image that would be looked up directly from the cdn now what is the cdn it's basically a geographically distributed uh data store which we will be using for sending out images throughout the whole world so let's just say i'm connecting from india somebody's connecting from us they want to look up for an image of a particular hotel so i'll look up on the cdn server which is in india the other person will look up into the cdn server which is in u.s okay so this becomes the hotel life cycle management the next thing is basically let's just say each time a modification is happening to a hotel let's just say a new hotel comes in we want to bubble up this hotel to the users who are going to search for this right now there are multiple ways in which we can send out this information to the search piece right i'll be using a kafka here so each modification that is happening within hotel service will flow through a kafka cluster and there'll be multiple consumers that will be sitting on top of this cluster which will populate their data store for serving the search traffic and for other traffic results right so one of the consumers will be the search consumer what happens is let's say a hotel gets a new room for example right there will be a payload that is put into kafka which has all the information that is required right now the search consumer pop pulls up the payload from kafka and it stores into its own database and this database would be used to power the search on the website okay now for search i am using an elastic searcher elasticsearch is basically a database that is built on leucine platform similar instead of elasticsearch you could also use a solar hair both are kind of similar components ideally it would depend on what infrastructure is being used in your company you could use that right but the idea of using elasticsearch is that i want this piece to be supporting fuzzy search now let's just say i am searching for a hotel in maldives or let's say user is searching for a hotel in maldives the user might not know the correct spelling right if they type in a wrong word i don't want them to get no results i would want this to be able to support a fuzzy search so i have to be able to handle all the typos and spelling mistakes and all of that plus i also want to give similar similarity kind of a thing there so that's the reason i'm using elastic structure so all the data of each individual hotel flows through the kafka via the search consumer into this elasticsearch cluster okay now on top of this elasticsearch fits the service form now again let's just say there's a spike in traffic i can infuse the number of nodes in kafka cluster i can increase the number of search consumers here and i can increase the number of nodes in elasticsearch cluster so till now whatever we have talked about is again horizontally scalable right and again coming to search service this is the service which powers the search on the website now website is i'm using a generic term sometimes i'll use a website sometimes i'll say ui but it's basically all modes of communication through which a user can come in that could be a app that could be a website right so the user talks to through again a load balancer to the search service whenever they want to search for a particular hotel again they will give a date range and a location for example as a search criteria and along with that they could also provide some tax now that tax would be the properties of the hotels so again going back to my previous example a five year is attacked a beachfront property is attack now the search on elasticity would be happening on either of these stacks and the ranges that are provided basically the date range price range and all of that okay so this takes care of the search flow now once the user has seen some of the results on the website they would want to book a hotel right the booking again happens through this ui so i've made this ui um saying that it's a search and book ui it will be the same app or the same website so which they are searching and then booking right now booking ui a booking request again comes to this load balancer and talks to booking service booking service essentially again sits on top of a mysql database now these are two different mysql clusters i am purposefully not using a same cluster here although we could use the same cluster and have two different databases in that but because we are talking about a fairly large system that has like a good enough amount of scale i would want to keep different clusters so as to you know take care of the scaling separately of each other okay now this are whenever a booking happens that booking gets stored into this mysql we go over the exact flow of booking when we go over the details of implementation within the booking service but essentially this stores the data into this mysql and it talks to a payment service normally what will happen it'll a booking request will come it stores something it will send the request for payment once there's a success it will mark the booking confirm right uh now again whenever a booking is happening the data is flowing into the same kafka right why so let's just say there was just one room available in a hotel right and that room is now booked i want to make sure that this hotel is not available for search now in that same day train because it's not available right so all of those information is again sent to the same kafka which is read by search consumer and then it takes care of even removing the hotels which are now completely booked now if you can see there's something called an archival servicer what i have done is i am just storing the live data into my sequel by live data i mean the bookings that are done but have not been completed thereby making sure that this is having a scale which is low enough that my sql can easily handle and once the booking moves to a terminal state so let's say booking is cancelled or booking is completed it will move through the archival service to a cassandra cluster the reason i'm using a cassandra here is so cassandra is a very good database which can handle a huge amount of reads and writes okay it has a concern that it needs a partition key on which all the queries should happen so let's say if i want to search by a booking id my partition key has to be a booking id in that case i cannot do any kinds of queries on a cassandra therefore i did not use a cassandra as a source of root database because on this database i need to do a large variety of queries we'll come to all of those when we look go into the detail of booking service but once it is archived we just need to do gets on those so therefore cassandra makes a good enough sense overall now once the booking is done all of that is fine but now we need to notify all the people right so then comes the notification service so let's say whenever a booking is made or any changes are happening into a booking or it moves into a terminal state there'll be a notification service that consumes events from this kafka and notify the people so for example on each booking we need to notify the hotel right whenever a booking is cancelled by the hotel we need to notify the consumer or in fact on each booking we need to notify the consumer with an invoice right so all of those is taken care by this notification service cool now coming back to the ui for hotels and users so each time a booking is done or even without that a user might want to see their old bookings or a hotel might want to see all the bookings that they have this is more of a read-only view for them right that will be powered by this booking management service which talks to now two data sources it talks to the mysql cluster for all the active bookings which are to happen sometime in future and to the cassandra cluster for the bookings that have already happened right now i am adding a radius on top of this mysql to reduce the load on this mysql so redis will act as my cache and whenever i have a query so for example something like get bookings of a user so i can cache this result into the thread and it'll be a right through cache so whenever a new booking is coming in this will get updated all right now this is the functional flow the bigger component here is how do we do the analytics on this so let's just say a business person wants to know how much revenue i'm making or how many bookings i'm having or what are my best performing hotels and stuff like that so they need to do a lot of analytics now mostly while designing the system we'll never always know what kind of analytics is required right so what i've done for that is i've used a hadoop cluster on which i'm pushing in all the events that are going into my kafka which is basically information about all my hotels about all my bookings about all the transactions that happen in my system right so there will be a spark streaming consumer that runs somewhere that reads from this kafka and puts all the data into a hadoop cluster on which i can do hive queries or any different kind of queries and build up a lot of reporting right so this is overall how the system look like it looks like and how the data flows now let's go into the details of some of the components now let's look at what hotel service internally is so it's not a very complicated service it is basically a credit service which provides create update redelete operations on the hotel data store and it is the source of truth for hotel data now this is not an exhaustive list of neither the apis nor the db schema that you see here there will be a lot more things but this will give you a feel of how it should be okay so let's look at some of the apis there'll be a post api slash hotels to create a hotel which will be part of their onboarding process um there will be a get api with an id slash hotel slash hotel id which will give back the information of the hotel which can be rendered on the screen and the hotel guy can see it now there will be a put api flash hotel slash id which will be used to update any information of a hotel similarly there will be a port api slash photos flash hotel id slash room slash room id which would be used to update the room information or create new rooms and all of that now this is not an exhaustive list there'll be a lot more api than you can add it as in when you know there's a requirement to add now let's look at how the db schema might look like so there are a couple of important tables now this is again not an exhaustive list of databases of the tables so there's one hotend table into this hotel db but before that everything in red here is either a primary key or a foreign key everything in blue is just a column now this hotel table contains your very standard things id name locality id which is a foreign key to locality table description original images display images and is active now i have two columns for original and display images so original images is basically what the artifact that the people have uploaded display images could be a compressed version of that that we've compressed it could be a version that we have uploaded on the cdn it could be uh something different than the original up image but we still need to keep both of them so we have stored it his active is basically a like a delete plan okay then coming to rooms table it has a room id obviously a hotel id which references into this table a display name which could just be a identifier to tell the customer on what kind of a room it is is active against again a delete flag quantity basically tells how many such rooms are there in the hotel and the price min and the price max now i do have do we have two prizes remember the hadoop cluster that we had in the original design that we made it has all a lot of data about various kinds of things we might as well run a machine learning model onto it and do some supply demand analytics and then come up with the optimal price right let's say supply is um low there's a lot of demand there are just a few rooms left might as well increase the price or let's say if there are too many rooms and very few customers might as well reduce the price right so this price min and price max could be the ranges which the hotel provides wherein the price could be fluctuated by the system a good starting point could be an average of both these sizes right then there's a facilities table which is basically a list of all the facilities that a hotel and a room can possibly have and these hotels facilities and room facilities are basically a mapping table which is a many-to-many relationship between a hotel id and a facility id again is access flag everywhere is basically a delete flag now again this is not a full list of tables there are a lot of information missing i've skipped the auditing information as your bookkeeping information like created on updated time and all of that a lot of information missing but this will give you a fair enough idea and it will be a good starting point for you to come up with a db schema for this one more thing to note here that if you remember the original design that we had i did not keep a redis cache on top of this mysql database but i did keep a redis cache on the other mysql database which was for booking table now why is that we could have kept the cache on top of this and all these get apis could have been a bit more fastest right but this is not coming in the critical path of any high throughput business interaction right so all the customers are not wearing this data neither does this service they are always querying the search service so if this service is a little bit slow that's okay but adding a redis cluster is a cost so you need to do a trade-off analysis between what cost are you adding of an infrastructure and what benefit it adds to you if it is worth it you might as well go and add a redis cluster here but i don't think it is worth it and that's the reason i did not add it now let's look at the internal functioning of the booking service we'll first start off just walking through the db schema again it's not a full-fledged schema there are a lot of details nothing like bookkeeping information like created time updated time and all of that but let's focus on the meaty part here okay so it has a table called available room which has a room id it has a date it has an initial quantity that comes from the hotel service and it has a available quantity available quantity is basically the number of rooms that are remaining for that particular room id for that particular date okay now it has a constraint saying it cannot go negative here is where the true power of my sequel we are utilizing and that's the reason why i chose to use my sql here okay the other table here is a booking table uh it has a booking id which is the primary key here which will be referenced across the whole system it has a room id again comes from the room table it has a user id a start date and an end it for a particular booking number of rooms which is how many rooms the person has booked status and an invoice id okay now looking at this design we can clearly understand that one booking cannot contain different room types you can have multiple rooms of the same room type but you cannot have like one deluxe room and one regular room one booking if you want that there'll be a small change required but i think that's a minor detail it can be taken care of easily okay the important part here is the status quo it has these four values reserved booked cancelled and completed and now canceled and completed are the terminal status is here so the booking gets first created into reserved status then when based on the payment success it can either move to book or cancel and once the user stays in that it moves to complete it now you can add more statuses depending upon your conversation with your interviewer but these four statuses are the main ones that will help us achieve what we initially thought of okay now let's look at the api signature so this will have one important api called a book api it will be a post api which will take these five attributes it will contain a user id it will contain a room id it will contain the quantity now again if you want to make multiple rooms multiple quantity we'll have to change it a bit to have an array but let's stick to this for now it'll have a started and it'll have a end it the price will come from somewhere else let's assume for now it'll actually come from the data store which contains the price for the room at this point in time we don't want to generally take the price from the user because then the request can be tampered with and that's not really a good design okay now let's do a quick revision of the design because i skipped some important details in the earlier larger diagram and we'll go over that now so the way booking service actually works is when it gets a request to do a booking it first of all queries this table and the available rooms table and check whether or not i have that many number of rooms remaining or not so if there are no rooms left for that particular room id for that particular day there's no point of proceeding so we can error out from that but in case that's a success and we have rooms then we actually go ahead with the blocking of the room saying that now i'll block it temporarily and if the payment is success i'll actually book the room i'll do a quick dry run of what actually happens assuming this is the request that came in user id 1 2 d5 quantity 1 for some date dt to dt plus 1 okay the room id 5 on that particular dt has 7 available rooms so our first check is a success that we have enough room so what essentially will happen is there'll be a row created in this table with a booking id some uuid room id 5 user id is 1 start date is dt whatever that is and it would be dt plus 1 whatever that is number of rooms in the request is quantity one okay and status would be at this point in time result okay invoice id at this point in time would be null because there is no invoice created till now okay now we have a record okay along with that we also decrement the quantity here now here again we are utilizing a very important feature of mysql which is the asset drop part of the asset property and transactions okay so we are creating a record here and we are reducing the quantity here to 6. what essentially we are trying to do is basically bounding this as part of one transaction so let's say there was just one room left and two three requests came in only one transaction would be successful to do both these things basically insert this record and reduce the quantity because we have this constraint sitting over here which says that quantity cannot be negative okay so only once of the transaction will be success and only one of the rooms will be booked and no two users will be redirected to payment okay now that being taken care of what is the next step so i have written down the steps here if you want to actually look at so what we have gone through till now is step number one and step number two okay we've inserted in booking and reduces reduce the quantity in available rooms our step number three is something that i did not cover as part of the larger design review because it was getting too much clutter now we cannot keep this room reserved for an infinite amount of time what we can say is if the payment is success in next five minutes well and good if not then we'll assume that the payment will not go through and will unblock the room so that somebody else could book it okay so there are multiple ways to implement that what i choose to implement here is something using the time to live off redis okay so because we anyway are using error disk we can utilize the same cluster of radius for this use case as well so what we'll do is we'll put the key in redis saying some booking id expires at some time time now the time stamp could be a configurable number it could be a fixed timestamp across the board it could be a country specific time thing for india have a time expiry time of five minutes for us have expiry time of four minutes something of that chart but whatever that time is we'll insert that into redis now what redis does is it has something called callbacks so one of the later versions of redis has introduced this concept called callbacks so whenever a key is getting expired you'll get a notification okay and you can do whatever you need to do at that point in time right so if the if you get a success notification from payment then good success notification means the payment has gone through then you will mark the booking as booked but before that if you get a call back from redis saying that the key has expired and you've not got the success from payment you will say that the booking is cancelled right alternatively you could also get a failure from payment saying for whatever reason the payment didn't go through and you got a failure response from the payment service and that again you can say cancel right now if you want a bifurcation of the varieties of cancer you can maybe make multiple events that cancel because of invoicing cancel because of payment cancel because of expiry whatever right or you could maybe add a status in column something of that chart but that's a very minor detail we'll skip that for now okay so let's go over what all possibilities are there in this and how each of them behaves okay so first very simple thing is what happens when payment is a structure so in case payment is a success everything remains the same just the status becomes booked okay in that case we do get some invoice id as well okay so basically we'll create we'll get an inverse id from payment service whenever you know a booking is getting success and we'll just update the invoice id there and then the regular kafka events would also be sent saying the booking is now complete and here's the kafka event for that in case somebody wants to do something on that okay what happens when payment fails now in this we just have these four statuses so the booking status will become cancelled okay there would be no invoice id in this case why because if the payment did not go through there obviously is not an invoice that is generated so and everything else remains the same but if the payment did not go through we need to revert the available quantity again so available quantity in that case would become seven okay now let's say your key expired so basically let's say the user was redirected to payment screen and there was no response from payment service for whatever reason what happens then if we get a call back from redis and based on that call back we can say that okay now the payment has not gone through we will follow the same process as payment failure we will mark this cancelled okay we will mark this cancer and we'll increment the quantity in available quantity so that the room is now available for somebody else to use again in that scenario there is no invoice generated okay but this you do only if the status is without why coming to the next case what happens if both three and one happen what happens if you get a key expiry event and a payment is also structured so there are two conditions if the payment has already been successful and the booking has already been moved to book status after that if you get this key expired event then you don't do anything because that is any way bound to happen right uh but what if it happens the other way around what if key expired first you move the booking to cancel state but then you get a notification saying payment to success right now there are multiple directions in which you could take it based on your conversation with your interviewer and the non-functional requirements and in fact even the functional requirements for that matter you could do two three things you could now either reverse the payment saying for whatever reason we were not able to book the room so here's your payment back alternatively you could do something even more smarter you could say that now i have anyway got the payment from the user i check if there are rooms available and i'll book them right now this could be done based on what the requirement is and you could talk to your interviewer and implement it either way okay and now all good so far but there are a couple of caveats here the ttl that you have talked about it is not a very precise measure so let's just say that a key was supposed to expire at 10 0 0 okay you will not you will probably never ever get a call back at this point in time it will always have some delay now in this case it doesn't matter too much instead of at 10 0 0 if you get it at 10 hours and one minute it's possibly okay also so it's not because too big of a problem and the reason for that is because of the way expires are implemented in redis i'll not go too much into detail of that but there's a background process that runs into red is for keys that are not accessed and whenever that process gets to access a particular key is when it will expire so it is not necessary that it will acquire it at exactly the same time okay but let's say if you wanted it to be totally precise then you could possibly tweak the implementation a bit and do a slightly different way so instead of doing a ttl based approach you could in fact implement a queue with it within redis and have a polar that kind of queries red is the topmost node of the queue every one second and whichever one it it finds has expired then you could kind of delete that but that's not that's obviously much better but that comes at a cost so you'll have to build a kind of a polling mechanism so that's additional development effort and then it will be continuously bombarding reduce every one second so there's a lot of cpu being utilized on both the sides on the crown side and on the red side so possibly you'll have to add more nodes into the redis cluster and also on the side where cron is being developed so now that's a tradeoff do you want to be notified absolutely immediately when the keys are supposed to be expired and at the cost of additional hardware that trade-off you can again make with the conversation with your interviewer but otherwise all of this being said i would still go with a ttl based approach because in this particular example it doesn't really matter so much now a couple of optimizations you could do so let's just say payment is success you know that e will expire after some time for sure right because it's there and that is you don't need to keep that key there you know the payment is success you can evict the key right even if the for the payment failure case you know that payment has failed it will expire after five minutes might as well delete the key then there right so these are certain optimizations that you could do over this implementation to make it even more better but on and off this is how the booking flow works now again reiterating we have used a couple of important features of my sequence and that's what is helping us to make the code on application side much more smoother had we used some other database which doesn't provide for example if you were using cassandra here we would not have had access to the transactions and the constraints and all of that you would have to implement it on application site that's additional effort on our site to make sure things are consistent in this case i would rather leave it to mysql to implement all of those things now coming back to the same architecture again i just want to call out that all of the components that you see here are individually horizontally scalable so let's just say there's a traffic spike happening on one of the components we could increase the number of nodes in that particular service maybe that particular database and then that should work just fine as far as kafka and hadoop cluster are concerned we could add more nodes into that as well and they should also scale to a much larger scale than what we need cool so now let's look at what kind of alternates that we could have used instead of this particular design choice right so first of all why my sequel we could use any other relational databases we could use a postgres we could use a sql server anything which provides asset guarantees should be fairly fine here as far as reddish is concerned we could use a memcache or any other cache instead of radius and that should also be good okay cassandra i would still stick to capacitor because that is exactly what we need here now technically in place of cassandra we could also use a hbase here that would also work fine but it has a lot of operational overhead in terms of deployment and maintaining it over time so that's the reason i would prefer cassandra over hbs or any other similar system where cassandra works is every data in cassandra is you know sharded across a partition key so each query has to happen on a partition key now the queries that we are doing are just of two varieties get bookings by hotel or get bookings by user there is no the third variety so we basically have two kinds of data which is distributed by two different partition keys on which the queries are happening so this would be kind of a very good choice here we could have used an active mq or a rabbit mq or any other queueing mechanism um there's an amazon queue also we could have used that but i think kafka skills much better than most of them so i think it's a fairly good charger other than that in general we definitely need to monitor how are our cpus and memory is behaving so if i have a cpu spike at certain points in time that is something we need to kind of look at so across the whole infrastructure we need to keep an eye on how my cpu usage percentage percentages how my memory usage percentage is how my disk usage for radius is how my disk usage for elastic searches all of these things are what we need to monitor now monitoring could be done through a grafana kind of a tool on which i can set up alert so if the let's say a particular metric has some threshold the moment i cross that threshold or with certain conditions i could send out an alert and the team could get notified that something is potentially wrong and they need to look at that this will help us to make sure that we in the end achieve our nfrs that we talked about of latency and high availability because let's just say something goes on let's just say memory is you know utilize more than what we expected eventually it will lead to some machines going down and eventually it will lead to us having a lower availability that than what we expected so yeah these are the things that we need to monitor and alert on now in the next section let's look at how this whole thing would be spread across geographies so for example let's say there's an earthquake in one of the data centers and everything just goes away out of the blue what do we do so let's look at that next so let's say we have these four data centers data center 1 data center 2 data center 3 and data center 4 which are located in different geographical regions across the globe okay now we want to create a topology in a way that we do get low latency and high availability okay so one very simple approach that we could do is say that bc one is our primary and all the three dc's are our secondary data centers and data is replicated to all the three data centers in near real time okay so that's okay it's good enough but it's not very good to be honest because we are just using 25 percent of our capacity as primary which is active and press three data centers are sitting idle and not really doing anything okay so let's try to improvise what we could instead do is divide the data centers and the globe into two parts okay what we could say is this is region one and this is region two okay now the countries or people accessing our services who are closer to this region will connect to this region and the people who are closer to that region will connect to that region right now how are we able to do that so the data in a hotel management system is fairly specific to a geography so all the hotels in let's say india can be you know separated from all the hotels in u.s similarly all the rooms all the bookings are now specific to hotels and they're specific to geography so we could kind of bifurcate the data as per geography right which gives us the leverage to divide the system into two halves right now what will happen here now let's just say dc1 is the primary in this region and dc3 is the primary in r2 okay now if dc1 goes down all the data and dc1 is getting replicated to dc2 in near real time so if that goes down dc2 can become active and all the clients who are connecting to dc and how will they connect so there will be bunch of clients who are connecting via some dns to dc1 right if this goes down dns can flip and connect to dc2 if this link is broken right similar thing can happen on this side so this way what we have is basically dividing our infrastructure into two halves thereby clients who are closer to this region are connecting to the servers that are closer to them thus giving them lower latency right now we could go even one step further we could say that we'll divide the region into four parts and we could do we could go as much as deep we want into this to increase the latency basically to reduce the latency and increase the availability but i think for all practical purposes at least for a hotel management system this r1 r2 thing is more than sufficient to give us a good enough latency and a very high availability so i think yeah that should be it for a hotel management system thanks for watching this video if you have any suggestions on what videos we should make next or how we could improve this one do let us know by commenting here and don't forget to subscribe to this channel and share the videos with your friends while we keep bringing you more such content happy learning